{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fy0xrRUDU8-m"
   },
   "source": [
    "### Spacy\n",
    "It is a framework that performs index preserving tokenization in action -  preserves this “link” between the word and its place in the raw text. It converts the tokens each of length 300.The spacy Pre-trained word vectors are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vdD86U3RV7Tm"
   },
   "source": [
    "#### Run the following to download the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DIo_WNdaUPkp"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isoqpqYZWDpJ"
   },
   "source": [
    "#### Run the following to load performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3WLfhy4LWEZe"
   },
   "outputs": [],
   "source": [
    "# pip install keras-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ep6j98GgWOj_",
    "outputId": "a1338836-acb1-46fc-e176-16a6b20d616c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Required Libraries\n",
    "import spacy.cli\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import warnings\n",
    "import keras_metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.collocations import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yncxfj9TW7Tl"
   },
   "source": [
    "#### Spacy to pre_trained vocabulary set, download and load it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LugK6mkjW7lY"
   },
   "outputs": [],
   "source": [
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2q6ipvydXVqP"
   },
   "source": [
    "#### Load the dataset from the csv files\n",
    "* Training : P1_training_set.csv\n",
    "* Testing : P1_testing_set.csv\n",
    "\n",
    "\n",
    "Create a collective dataset (df) - to perform pre-processing uniformly on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Km3Kt3B6Xa3P"
   },
   "outputs": [],
   "source": [
    "df_train_org = pd.read_csv(\"P1_training_set.csv\")\n",
    "df_train_shuf = shuffle(df_train_org)\n",
    "\n",
    "df_test_org = pd.read_csv(\"P1_testing_set.csv\")\n",
    "df_test_shuf = shuffle(df_test_org)\n",
    "\n",
    "frames = [df_train_shuf, df_test_shuf]\n",
    "df = pd.concat(frames, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TE6gaA9vYQaH"
   },
   "source": [
    "### Preprocessing\n",
    "- Word Tokenize : Convert the sentences into Tokens\n",
    "- Use the stopwords and punctuation list from nltk to clean the word tokens\n",
    "- Use WordNetLemmatizer to convert words to their base form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SsFnxjvXdQD"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    sent = ''.join(i for i in text if not i.isdigit())\n",
    "    word_sent = word_tokenize(sent)\n",
    "    _stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "    st = WordNetLemmatizer() \n",
    "    _stopwords.add(\"'s\")\n",
    "    word_sent = [st.lemmatize(word) for word in word_sent if word not in _stopwords]\n",
    "    return word_sent\n",
    "\n",
    "for i in df:\n",
    "    df['process_E1'] = [preprocessing(i) for i in df['Event 1']]\n",
    "    df['process_E2'] = [preprocessing(i) for i in df['Event 2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1G9VSdYhYdx7"
   },
   "source": [
    "### Spacy word Embedding\n",
    "* Convert the words into vectors each of length 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nf_mWSOQYlNy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list_E1 = []\n",
    "for j in df['process_E1']:\n",
    "  res = [0] * 300\n",
    "  val = [0] * 300\n",
    "  length = len(j)\n",
    "  for token in j:\n",
    "    res  = res + (nlp.vocab[token].vector)\n",
    "  val = res/length \n",
    "  list_E1.append(val)\n",
    "\n",
    "import numpy as np\n",
    "list_E2 = []\n",
    "for j in df['process_E2']:\n",
    "  res = [0] * 300\n",
    "  val = [0] * 300\n",
    "  length = len(j)\n",
    "  for token in j:\n",
    "    res  = res + (nlp.vocab[token].vector)\n",
    "  val = res/length \n",
    "  list_E2.append(val)  \n",
    "  \n",
    "event_concat = list(map(lambda x, y: list(x) + list(y), list_E1, list_E2))\n",
    "df_vec = pd.DataFrame(list(zip(list_E1, list_E2, event_concat, df['Label'])),columns = ['List_E1', 'List_E2', 'Total Event','Label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "00YW5-NwZKAv"
   },
   "source": [
    "### Input and Output Dataset\n",
    "* df_vec['Total Event'] - X : Input\n",
    "* df_vec['Label'] - Y : Output\n",
    "* Training : 70% of the Dataset\n",
    "* Testing : 30% of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_KVFWIWZU5G"
   },
   "outputs": [],
   "source": [
    "X = df_vec['Total Event']\n",
    "y = df_vec['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.30, random_state=42)\t\t\t\t\t \n",
    "X_train = sequence.pad_sequences(X_train)\n",
    "X_test = sequence.pad_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIqdYb_9ZhpL"
   },
   "source": [
    "### Model 1\n",
    "- Sequential Model\n",
    "- 100 units - LSTM\n",
    "- Dense Layer - 1 hidden unit with \"sigmoid\" activation function\n",
    "- Dense Layer - 1 hidden unit with \"softmax\" activation function\n",
    "- Optimizer - \"rmsprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "GtHUoVCxZm4H",
    "outputId": "d2c0c695-5abb-40db-e78f-ca0637fb9413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 600, 500)          5000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               240400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 5,240,503\n",
      "Trainable params: 5,240,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "6276/6276 [==============================] - 117s 19ms/step - loss: -2.6240 - acc: 0.3985 - precision: 1.1646 - recall: 1.0000\n",
      "Epoch 2/3\n",
      "6276/6276 [==============================] - 117s 19ms/step - loss: -2.6240 - acc: 0.3985 - precision: 1.1646 - recall: 1.0000\n",
      "Epoch 3/3\n",
      "6276/6276 [==============================] - 116s 19ms/step - loss: -2.6240 - acc: 0.3985 - precision: 1.1646 - recall: 1.0000\n",
      "Accuracy   : 0.404\n",
      "Precision  : 1.16\n",
      "Recall     : 1.0\n",
      "Loss       : -2.49\n",
      "F1-Score   : 1.07\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(10000, 500, input_length=600))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.add(Dense(1, activation=\"softmax\"))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall()])\n",
    "\n",
    "print(model1.summary())\n",
    "\n",
    "# Training Phase - Fit the model\n",
    "model1.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "\n",
    "# Testing Phase - Evaluate the model\n",
    "scores = model1.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Performance Metrics\n",
    "print('Accuracy   : {:2.3}'.format(scores[1]))\n",
    "print('Precision  : {:2.3}'.format(scores[2]))\n",
    "print('Recall     : {:2.3}'.format(scores[3]))\n",
    "print('Loss       : {:2.3}'.format(scores[0]))\n",
    "f_score = (2.0 * scores[2] * scores[3]) / (scores[2] + scores[3])\n",
    "print('F1-Score   : {:2.3}'.format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Oq88ZXRZtwJ"
   },
   "source": [
    "### Model 2\n",
    "- Sequential Model\n",
    "- 100 units - LSTM\n",
    "- Dense Layer - 256 hidden unit with - \"relu\" activation function\n",
    "- Dense Layer - 1 hidden unit with - - \"softmax\" activation function\n",
    "- Optimizer - \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "cIL4bmioZscP",
    "outputId": "b77307be-7623-4477-9111-fbe3437db054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 600, 500)          5000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               240400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,266,513\n",
      "Trainable params: 5,266,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "6276/6276 [==============================] - 117s 19ms/step - loss: -2.6240 - acc: 0.3985 - precision: 1.1646 - recall: 1.0000\n",
      "Epoch 2/3\n",
      "6276/6276 [==============================] - 116s 19ms/step - loss: -2.6240 - acc: 0.3985 - precision: 1.1646 - recall: 1.0000\n",
      "Epoch 3/3\n",
      "6276/6276 [==============================] - 117s 19ms/step - loss: -2.6240 - acc: 0.3985 - precision: 1.1646 - recall: 1.0000\n",
      "Accuracy   : 0.404\n",
      "Precision  : 1.16\n",
      "Recall     : 1.0\n",
      "Loss       : -2.49\n",
      "F1-Score   : 1.07\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(10000, 500, input_length=600\n",
    "                     ))\n",
    "model2.add(LSTM(100))\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dense(1, activation=\"softmax\"))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras_metrics.precision(), keras_metrics.recall()])\n",
    "\n",
    "print(model2.summary())\n",
    "model2.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model2.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Accuracy   : {:2.3}'.format(scores[1]))\n",
    "print('Precision  : {:2.3}'.format(scores[2]))\n",
    "print('Recall     : {:2.3}'.format(scores[3]))\n",
    "print('Loss       : {:2.3}'.format(scores[0]))\n",
    "f_score = (2.0 * scores[2] * scores[3]) / (scores[2] + scores[3])\n",
    "print('F1-Score   : {:2.3}'.format(f_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n22QoZAmaCHl"
   },
   "source": [
    "### Model 3 - Logistic Regression\n",
    "* Random state - 0\n",
    "* Solver - 'lbfgs' - limited memory optimization algorithm\n",
    "* Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "colab_type": "code",
    "id": "FTPOC8E4ac7j",
    "outputId": "bb59c5ba-1226-4870-80c3-c0282c8493dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qOJcftUDbne3",
    "outputId": "cd2f3564-001f-477f-c35e-0bb1daa1756c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "LogisticRegression   Accuracy : 39.4%\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "for i in range(len(cv_df)):\n",
    "  val  = val + cv_df['accuracy'][i]\n",
    "val = val/5\n",
    "print(\"---------------------\")\n",
    "print(cv_df['model_name'][i],'  Accuracy : {:2.3}%'.format(val* 100))\n",
    "print('---------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6M_mU1kEbpg6"
   },
   "source": [
    "### Performance Measure\n",
    "#### Google Colabs - GPU\n",
    "\n",
    "#### Model 1 - Sequential - LSTM(100),Sigmod(1), Softmax(1)\n",
    "* Accuracy   : 40.4%\n",
    "* Precision  : 1.16\n",
    "* Recall     : 1.0\n",
    "* Loss       : -2.49\n",
    "* F1-Score   : 1.07\n",
    "##### Computation Time: 6 mins\n",
    "\n",
    "#### Model 2 - Sequential - LSTM(100),Relu(256), Softmax(1)\n",
    "* Accuracy   : 40.4%\n",
    "* Precision  : 1.16\n",
    "* Recall     : 1.0\n",
    "* Loss       : -2.49\n",
    "* F1-Score   : 1.07\n",
    "##### Computation Time: 6 mins\n",
    "\n",
    "#### Model 3 - Logistic Regression\n",
    "* Accuracy : 39.4%"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Spacy Word Embedder new.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
