{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "TijwBTIsF7zi",
    "outputId": "208aa38e-23ba-4e84-fb9b-0207c56a6362"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TDMNRCNslqj2",
    "outputId": "e6dea61e-db19-43a0-e2fa-d6639fb18aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17.4\n",
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BL-mIAnFlszY"
   },
   "outputs": [],
   "source": [
    "BASE_PATH = 'http://export.arxiv.org/api/query'\n",
    "CATEGORIES = [\n",
    "    'Machine Learning',\n",
    "    'Natural Language Processing',\n",
    "    'Neural Networks',\n",
    "    'Artifical Intelligence'\n",
    "]\n",
    "KEYWORDS = [\n",
    "    'neural',\n",
    "    'intelligence'\n",
    "    'network',\n",
    "    'deep'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tu6OQN3Wl00G"
   },
   "outputs": [],
   "source": [
    "def build_url(amount, offset):\n",
    "    categories = ' OR '.join('cat:' + x for x in CATEGORIES)\n",
    "    keywords = ' OR '.join('all:' + x for x in KEYWORDS)\n",
    "\n",
    "    url = BASE_PATH\n",
    "    url += '?search_query=(({}) AND ({}))'.format(categories, keywords)\n",
    "    url += '&max_results={}&offset={}'.format(amount, offset)\n",
    "    \n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbVwmugKl4g0"
   },
   "outputs": [],
   "source": [
    "def get_count():\n",
    "    url = build_url(0, 0)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    count = int(soup.find('opensearch:totalresults').string)\n",
    "    print(count, 'papers found')\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C22MK_9Kl61O",
    "outputId": "0f9ce68d-5001-468e-aefb-233374d792eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67242 papers found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_papers = get_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqeQ6OI5l99u"
   },
   "outputs": [],
   "source": [
    "PAGE_SIZE = 100\n",
    "\n",
    "def fetch_page(amount, offset):\n",
    "    url = build_url(amount, offset)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    for entry in soup.findAll('entry'):\n",
    "        text = entry.find('summary').text\n",
    "        text = text.strip().replace('\\n', ' ')\n",
    "        yield text\n",
    "\n",
    "def fetch_all():\n",
    "    for offset in range(0, num_papers, PAGE_SIZE):\n",
    "        print('Fetch papers {}/{}'.format(offset + PAGE_SIZE, num_papers))\n",
    "        \n",
    "        for page in fetch_page(PAGE_SIZE, offset):\n",
    "            yield page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0oBP6WYmBIC"
   },
   "outputs": [],
   "source": [
    "# DOWNLOADED_FILENAME = 'arxiv_data_abstracts.txt'\n",
    "DOWNLOADED_FILENAME = 'sample_data.txt'\n",
    "\n",
    "def download_data():\n",
    "    if not os.path.isfile(DOWNLOADED_FILENAME):\n",
    "        with open(DOWNLOADED_FILENAME, 'w') as file_:\n",
    "            for abstract in fetch_all():\n",
    "                file_.write(abstract + '\\n')\n",
    "    with open(DOWNLOADED_FILENAME) as file_:\n",
    "        data = file_.readlines()\n",
    "        \n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjOeqwqnmFS1"
   },
   "outputs": [],
   "source": [
    "data = download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWEu6AOEmIHO"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "BATCH_SIZE = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ur5sgaUXrI2M"
   },
   "outputs": [],
   "source": [
    "VOCABULARY = \\\n",
    "        \" $%'()+,-./0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ\" \\\n",
    "        \"\\\\^_abcdefghijklmnopqrstuvwxyz{|}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFtM-mR_rKlQ"
   },
   "outputs": [],
   "source": [
    "lookup = {x: i for i, x in enumerate(VOCABULARY)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UhBBCitvrMgA"
   },
   "outputs": [],
   "source": [
    "def one_hot(batch, sequence_length = MAX_SEQUENCE_LENGTH):\n",
    "    one_hot_batch = np.zeros((len(batch), sequence_length, len(VOCABULARY)))\n",
    "\n",
    "    # Iterate through every line of text in a batch\n",
    "    for index, line in enumerate(batch):\n",
    "        line = [x for x in line if x in lookup]\n",
    "        assert 2 <= len(line) <= MAX_SEQUENCE_LENGTH\n",
    "        \n",
    "        # Iterate through every character in a line\n",
    "        for offset, character in enumerate(line):\n",
    "            # Code is the index of the character in the vocabulary\n",
    "            code = lookup[character]\n",
    " \n",
    "            one_hot_batch[index, offset, code] = 1\n",
    "    \n",
    "    return one_hot_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3UfBMDKarQUI"
   },
   "outputs": [],
   "source": [
    "def next_batch():\n",
    "    windows = []\n",
    "    for line in data:\n",
    "        for i in range(0, len(line) - MAX_SEQUENCE_LENGTH + 1, MAX_SEQUENCE_LENGTH // 2):\n",
    "            windows.append(line[i: i + MAX_SEQUENCE_LENGTH])\n",
    "\n",
    "    while True:\n",
    "        random.shuffle(windows)\n",
    "        for i in range(0, len(windows), BATCH_SIZE):\n",
    "            batch = windows[i: i + BATCH_SIZE]\n",
    "            yield one_hot(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KKAHIQrirTFU",
    "outputId": "43e87aa1-8dbf-4108-ad07-8e8aabb1e0a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 100, 83)\n"
     ]
    }
   ],
   "source": [
    "test_batch = None\n",
    "for batch in next_batch():\n",
    "    test_batch = batch\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRbCvoaSrbo_"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkvBcBeOrgS3"
   },
   "outputs": [],
   "source": [
    "sequence = tf.placeholder(tf.float32, [None, MAX_SEQUENCE_LENGTH, len(VOCABULARY)])\n",
    "\n",
    "X = tf.slice(sequence, (0, 0, 0), (-1, MAX_SEQUENCE_LENGTH - 1, -1))\n",
    "\n",
    "y = tf.slice(sequence, (0, 1, 0), (-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NJQSAHskrmRH"
   },
   "outputs": [],
   "source": [
    "def get_mask(target):\n",
    "    mask = tf.compat.v1.reduce_max(tf.abs(target), reduction_indices=2)\n",
    "    return mask\n",
    "\n",
    "def get_sequence_length(target):\n",
    "    mask = get_mask(target)\n",
    "    sequence_length = tf.compat.v1.reduce_sum(mask, reduction_indices=1)\n",
    "    \n",
    "    return sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMpHtXcjrpXd"
   },
   "outputs": [],
   "source": [
    "num_neurons = 200\n",
    "cell_layers = 2\n",
    "\n",
    "num_steps = MAX_SEQUENCE_LENGTH - 1\n",
    "num_classes = len(VOCABULARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00U2pkk4rr7N"
   },
   "outputs": [],
   "source": [
    "sequence_length = get_sequence_length(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1nxg_vIRrvRx"
   },
   "outputs": [],
   "source": [
    "def build_rnn(data, num_steps, sequence_length, initial=None):\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_neurons)\n",
    "\n",
    "    multi_cell = tf.nn.rnn_cell.MultiRNNCell(\n",
    "        [tf.compat.v1.nn.rnn_cell.LSTMCell(num_neurons) for _ in range(cell_layers)])\n",
    "\n",
    "    output, state = tf.nn.dynamic_rnn(\n",
    "        inputs=data,\n",
    "        cell=multi_cell,\n",
    "        dtype=tf.float32,\n",
    "        initial_state=initial,\n",
    "        sequence_length=sequence_length)\n",
    "\n",
    "    # Shared softmax layer across all RNN cells\n",
    "    weight = tf.Variable(tf.truncated_normal([num_neurons, num_classes], stddev=0.01))\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[num_classes]))\n",
    "\n",
    "    flattened_output = tf.reshape(output, [-1, num_neurons])\n",
    "\n",
    "    prediction = tf.nn.softmax(tf.matmul(flattened_output, weight) + bias)\n",
    "    prediction = tf.reshape(prediction, [-1, num_steps, num_classes])\n",
    "\n",
    "    return prediction, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "id": "R9sn-8Onrxfx",
    "outputId": "c31d31f6-207d-4197-f97f-18305c9e9238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-5af00fc01315>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-26-5af00fc01315>:5: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-26-5af00fc01315>:12: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "prediction, _ = build_rnn(X, num_steps, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zc3UShuRr84D"
   },
   "outputs": [],
   "source": [
    "mask = get_mask(y)\n",
    "\n",
    "prediction = tf.clip_by_value(prediction, 1e-10, 1.0)\n",
    "\n",
    "cross_entropy = y * tf.log(prediction)\n",
    "cross_entropy = -tf.reduce_sum(cross_entropy, reduction_indices=2)\n",
    "\n",
    "cross_entropy *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2UNV_ePsCpV"
   },
   "outputs": [],
   "source": [
    "length = tf.reduce_sum(sequence_length, 0)\n",
    "\n",
    "cross_entropy = tf.reduce_sum(cross_entropy, reduction_indices=1) / length\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KqL2PD8gsEuv"
   },
   "outputs": [],
   "source": [
    "logprob = tf.multiply(prediction, y)\n",
    "logprob = tf.reduce_max(logprob, reduction_indices=2)\n",
    "logprob = tf.log(tf.clip_by_value(logprob, 1e-10, 1.0)) / tf.log(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xN4BubZ0sHTk"
   },
   "outputs": [],
   "source": [
    "logprob *= mask\n",
    "\n",
    "length = tf.reduce_sum(sequence_length, 0)\n",
    "\n",
    "logprob = tf.reduce_sum(logprob, reduction_indices=1) / length\n",
    "logprob = tf.reduce_mean(logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "wRIeOmfOsKGv",
    "outputId": "0b4df51f-3782-4b25-dec4-e28e9d45ab03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(0.002)\n",
    "\n",
    "gradient = optimizer.compute_gradients(cross_entropy)\n",
    "\n",
    "optimize = optimizer.apply_gradients(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEYjGn38sLyQ"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "epoch_size = 50\n",
    "\n",
    "logprob_evals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fyrqIs82sOT_"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './sample_data_checkpoint_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "hMTjUlOCsQ1L",
    "outputId": "90644ca0-73cc-40ff-f8a2-3247243c268b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 perplexity 1.0178\n",
      "Epoch  1 perplexity 1.0178\n",
      "Epoch  2 perplexity 1.0178\n",
      "Epoch  3 perplexity 1.0174\n",
      "Epoch  4 perplexity 1.0127\n"
     ]
    }
   ],
   "source": [
    "perplexity_set = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for _ in range(epoch_size):\n",
    "            batch = next(next_batch())\n",
    "            \n",
    "            logprob_eval, _ = sess.run((logprob, optimize), {sequence: batch})\n",
    "            \n",
    "            logprob_evals.append(logprob_eval)\n",
    "            \n",
    "        saver.save(sess, os.path.join(checkpoint_dir, 'char_pred'), epoch)    \n",
    "        \n",
    "        perplexity = 2 ** -(sum(logprob_evals[-epoch_size:]) /\n",
    "                            epoch_size)\n",
    "        perplexity_set.append(perplexity)\n",
    "        print('Epoch {:2d} perplexity {:5.4f}'.format(epoch, perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "RRqU3lzxyZW2",
    "outputId": "9002b4ad-d623-4685-8804-47cc3da91fb8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0178333664259882,\n",
       " 1.0178311872369465,\n",
       " 1.0178023040861288,\n",
       " 1.0175435292276902,\n",
       " 1.0129018785322832,\n",
       " 1.012387913484009,\n",
       " 1.0123563375371132,\n",
       " 1.0123375463924995,\n",
       " 1.0123026607738421,\n",
       " 1.0123059796754068,\n",
       " 1.0122925123514084,\n",
       " 1.0122903165337562,\n",
       " 1.0122844132961535,\n",
       " 1.012287658687206,\n",
       " 1.0122747948357116,\n",
       " 1.0122717639532797,\n",
       " 1.0122714292221284,\n",
       " 1.0122580145297573,\n",
       " 1.012261418574398,\n",
       " 1.0122519680345579,\n",
       " 1.0122576516261097,\n",
       " 1.0122543860741744,\n",
       " 1.0122422225387393,\n",
       " 1.0122453373923337,\n",
       " 1.0122397677784358,\n",
       " 1.0122366933508904,\n",
       " 1.0122249658954885,\n",
       " 1.0122205033599778,\n",
       " 1.0122053391352082,\n",
       " 1.0121820242626098,\n",
       " 1.012149366586744,\n",
       " 1.0120777715160447,\n",
       " 1.011964080244161,\n",
       " 1.0118363690223395,\n",
       " 1.0117006581404504,\n",
       " 1.011546180359544,\n",
       " 1.0113310207974178,\n",
       " 1.011116601167856,\n",
       " 1.0108817282651412,\n",
       " 1.0106999018443195,\n",
       " 1.010554726424775,\n",
       " 1.0104162626290385,\n",
       " 1.0103067957592,\n",
       " 1.0101768715548631,\n",
       " 1.010075720867131,\n",
       " 1.009975751086736,\n",
       " 1.0098521061184071,\n",
       " 1.0097471241467075,\n",
       " 1.0096393274956739,\n",
       " 1.0095333247575151,\n",
       " 1.0094242833844478,\n",
       " 1.0093270255905624,\n",
       " 1.0092140678343071,\n",
       " 1.009120467294045,\n",
       " 1.009023392274284,\n",
       " 1.0089504236376858,\n",
       " 1.0088544518491802,\n",
       " 1.008744042812783,\n",
       " 1.0086754812816348,\n",
       " 1.0085887834496947,\n",
       " 1.008515074407499,\n",
       " 1.0084275205828463,\n",
       " 1.0083466165487047,\n",
       " 1.0082625900632,\n",
       " 1.0081895503399583,\n",
       " 1.0081068170073053,\n",
       " 1.0080440415189662,\n",
       " 1.0079821116802339,\n",
       " 1.007907770690235,\n",
       " 1.0078399236551498,\n",
       " 1.007785555393985,\n",
       " 1.0076996153102113,\n",
       " 1.0076277488460919,\n",
       " 1.0075598725032175,\n",
       " 1.0075178858651932,\n",
       " 1.007433903608529,\n",
       " 1.0073770037822944,\n",
       " 1.0073198697825627,\n",
       " 1.0072572482318234,\n",
       " 1.0071958691310565,\n",
       " 1.007130096534738,\n",
       " 1.0070890641734496,\n",
       " 1.0070272470650212,\n",
       " 1.0069706920822212,\n",
       " 1.0069090789698143,\n",
       " 1.006865557571742,\n",
       " 1.0068103773095063,\n",
       " 1.0067456254784166,\n",
       " 1.0066876420339468,\n",
       " 1.006668690491332,\n",
       " 1.0066043348366291,\n",
       " 1.006546322596882,\n",
       " 1.0064886531205839,\n",
       " 1.0064435658648085,\n",
       " 1.0064056366716798,\n",
       " 1.0063468483104063,\n",
       " 1.0062883719705853,\n",
       " 1.0062451830132606,\n",
       " 1.00618158489889,\n",
       " 1.0061570211441384]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykxUo2Wvz7Nh"
   },
   "outputs": [],
   "source": [
    "input_set = list(range(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "-aeQ_e3cz0Ua",
    "outputId": "e74e267c-a504-4d8a-97d0-be3a0c85b7c4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWkXBISIiraLgEBGRVlFwiIhIq/x/YsVcsE19/XwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(input_set, perplexity_set)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYvne6MnGEjq"
   },
   "outputs": [],
   "source": [
    "text = open('arxiv_mini.txt', 'r').read().lower()\n",
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMy5MZr9IGbL"
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IWtBwADWIVQV",
    "outputId": "439f659d-00c8-464b-ee7d-a186c54e65d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 172281\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_wU5dc0GoDB"
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "5UxGsMClGqka",
    "outputId": "0ad9478d-cb12-4344-9c3d-f4bfdad63457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(200, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(200))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "gMJgdr6zGwwf",
    "outputId": "8338e314-15f5-4041-ceaa-83b8cff91814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "coIg7h1NG0LE"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HB5mQL5uG4kF"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "# print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tCo87TXNHCV4"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = \"weights.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "58Bl1V44HFZu",
    "outputId": "6cfcb424-9927-442b-8760-b68a257dfa07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "172281/172281 [==============================] - 187s 1ms/step - loss: 2.8757\n",
      "\n",
      "Epoch 00001: loss improved from 2.88515 to 2.87570, saving model to weights.hdf5\n",
      "Epoch 2/5\n",
      "172281/172281 [==============================] - 188s 1ms/step - loss: 2.8745\n",
      "\n",
      "Epoch 00002: loss improved from 2.87570 to 2.87446, saving model to weights.hdf5\n",
      "Epoch 3/5\n",
      "172281/172281 [==============================] - 187s 1ms/step - loss: 2.8727\n",
      "\n",
      "Epoch 00003: loss improved from 2.87446 to 2.87267, saving model to weights.hdf5\n",
      "Epoch 4/5\n",
      "172281/172281 [==============================] - 187s 1ms/step - loss: 2.8721\n",
      "\n",
      "Epoch 00004: loss improved from 2.87267 to 2.87207, saving model to weights.hdf5\n",
      "Epoch 5/5\n",
      "172281/172281 [==============================] - 188s 1ms/step - loss: 2.8736\n",
      "\n",
      "Epoch 00005: loss did not improve from 2.87207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc15a655d68>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=1, min_lr=0.001)\n",
    "callbacks = [checkpoint, reduce_lr]\n",
    "model.fit(x, y, batch_size=100, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0xeA9rWFxwEa"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOVhZBsQ2j7x"
   },
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGH7D8PwQ4qd"
   },
   "outputs": [],
   "source": [
    "print(generate_text(1000, 0.3)) # Prediction  length = 1000; sampling temperature = 0.3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_NLG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
